# Dimensionality

## Pre-Reading

1. Chollet, [2.2 Data representations for neural networks](https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/Text/02.htm#:-:text=2.2%20Data%20representations%20,for%20neural%20networks).

2. **What's a Tensor?**, Dan Fleisch. You may want to speed up the video a tad:

- If you have experience in linear algebra, [start at 6:15](https://youtu.be/f5liqUk0ZTw?t=375)
- If you are seriously in a hurry watch at least [from 10:20 - 11:20](https://youtu.be/f5liqUk0ZTw?t=620)
- If you are new to linear algebra, watch the entire video.

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/f5liqUk0ZTw?si=02YMXVF0YpBT1FMF&amp;start=375" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Objectives

1. Understand how samples in a dataset can be represented as n-rank tensors.
2. Explore some of the consequences of high dimensionality in machine learning.
3. Identify a few ways to reduce dimensions.

## Lesson

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Lite\n",
    "\n",
    "Previously, we trained a model based on MobileNetV2 to differentiate between cats and dogs.\n",
    "\n",
    "Prior to conducting inference with this model, we will convert the model to Tensorflow Lite.\n",
    "This will have performance advantages on constrained hardware.\n",
    "\n",
    "## Pre-reading\n",
    "\n",
    "- [TensorFlow Lite](https://www.tensorflow.org/lite/guide)\n",
    "- [Pre-trained models for TensorFlow Lite](https://www.tensorflow.org/lite/models/trained)\n",
    "- [Model conversion overview](https://www.tensorflow.org/lite/models/convert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Recall our machine learning workflow for embedded systems:\n",
    "\n",
    "1. Decide on a goal\n",
    "2. Collect and understand a dataset\n",
    "3. Design a model architecture\n",
    "    - Design the data input pipeline\n",
    "    - Design the model itself\n",
    "    - Design outputs that meet the goal\n",
    "4. Train the model\n",
    "5. Evaluate the model\n",
    "6. Convert the model\n",
    "7. Run inference\n",
    "8. Iterate\n",
    "    - Troubleshoot\n",
    "    - Evaluate on-hardware performance\n",
    "    - Collect data for feedback\n",
    "\n",
    "In the previous lesson, \"Transfer Learning\", we completed steps 1-5. Now it is sime to convert the model to TensorFlow Lite so that it can be executed on a Raspberry Pi."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TF Lite\n",
    "\n",
    "### Upload the Model\n",
    "\n",
    "First, upload the saved model from the previous lesson (`cat-dog-tuned.zip`) into this Colab instance.\n",
    "\n",
    "Then unzip the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run after uploading the file\n",
    "!unzip cat-dog-tuned.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the saved model\n",
    "\n",
    "We'll use [TFLiteConverter](https://www.tensorflow.org/lite/api_docs/python/tf/lite/TFLiteConverter) to export the model to a single binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pT8t5BDynwh_",
    "outputId": "0a1e1b26-8e20-401a-ae47-dfec0979c374"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(help(tf.lite.TFLiteConverter))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the model we will open it and then follow [the docs](https://www.tensorflow.org/lite/models/convert/convert_models#convert_a_savedmodel_recommended_).\n",
    "\n",
    "**Notice that we are using [Dynamic Range Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization).** This is the default optimization.\n",
    "\n",
    "> This type of quantization statically quantizes only the weights from floating point to integer at conversion time, which provides 8-bits of precision.\n",
    "\n",
    "> Outputs are still stored using floating point so the increased speed of dynamic-range ops is less than a full fixed-point computation.\n",
    "\n",
    "However, this does not require us to calibrate the input range like full integer quantization does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = \"cat-dog-tuned\"  # path to the SavedModel directory\n",
    "tflite_model = \"cat-dog.tflite\"  # what to save the converted model as\n",
    "\n",
    "# Open the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "# Use Dynamic Range Quantization\n",
    "# https://www.tensorflow.org/lite/performance/post_training_quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Convert the model.\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(\"cat-dog.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the converted model\n",
    "\n",
    "You'll ultimately need to get your model onto a Raspberry Pi.\n",
    "\n",
    "Download your `.tflite` model now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Model Sizes\n",
    "\n",
    "There is some metadata that gets thrown out and some zip compression going on, but just for an order of magnitude estimate, compare the size of the full `cat-dog-tuned.zip` to `cat-dog.tflite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by file size and show in Human Readable format\n",
    "!ls -lhS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct inference on novel images\n",
    "\n",
    "Now that we've converted the model, let's test it with novel images!\n",
    "\n",
    "- First, use the full Keras API\n",
    "- Second, rely on the Tensorflow Lite runtime\n",
    "\n",
    "### Upload images\n",
    "\n",
    "The book has some sample images. Either download them or find your own and upload them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir img\n",
    "!wget -qP img/ https://raw.githubusercontent.com/USAFA-ECE/ai-hardware/main/book/dnn/cat-dog/img/cat1.jpg\n",
    "!wget -qP img/ https://raw.githubusercontent.com/USAFA-ECE/ai-hardware/main/book/dnn/cat-dog/img/cat2.jpg\n",
    "!wget -qP img/ https://raw.githubusercontent.com/USAFA-ECE/ai-hardware/main/book/dnn/cat-dog/img/cat3.jpg\n",
    "!wget -qP img/ https://raw.githubusercontent.com/USAFA-ECE/ai-hardware/main/book/dnn/cat-dog/img/dog1.jpg\n",
    "!wget -qP img/ https://raw.githubusercontent.com/USAFA-ECE/ai-hardware/main/book/dnn/cat-dog/img/dog2.jpg\n",
    "!wget -qP img/ https://raw.githubusercontent.com/USAFA-ECE/ai-hardware/main/book/dnn/cat-dog/img/dog3.jpg\n",
    "!ls img/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Use TF Keras API\n",
    "\n",
    "This requires the full tensorflow install. It uses the original model saved in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras API\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from time import process_time\n",
    "\n",
    "# Labels: 0 = Cat, 1 = Dog\n",
    "model = tf.keras.models.load_model(\"cat-dog-tuned\")\n",
    "\n",
    "# Where test images should be uploaded to\n",
    "dir = \"img/\"\n",
    "# Recursively iterate over all images in directory\n",
    "for root, dirs, files in os.walk(dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
    "            # Load and resize the image\n",
    "            file_path = os.path.join(root, file)\n",
    "            img = tf.keras.utils.load_img(file_path, target_size=(160, 160))\n",
    "            img_array = tf.keras.utils.img_to_array(img)\n",
    "            img_array = tf.expand_dims(img_array, 0)  # Create a batch of size 1\n",
    "\n",
    "            # Conduct inference and extract the result from the np array\n",
    "            start_time = process_time()\n",
    "            prediction = model.predict(img_array)\n",
    "            result = np.squeeze(prediction)\n",
    "            elapsed_time = process_time() - start_time\n",
    "\n",
    "            # Activation function\n",
    "            sig_result = tf.nn.sigmoid(result)\n",
    "            sig_predict = tf.where(sig_result < 0.5, 0, 1)\n",
    "            sig_predict = sig_predict.numpy()\n",
    "\n",
    "            print(\"Img:\", file)\n",
    "            print(\"Inference time\", elapsed_time)\n",
    "            print(\"Raw prediction:\", result)\n",
    "            print(\"Inferred label:\", sig_predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TF Lite Interpreter\n",
    "\n",
    "This more closely mirrors what we'll do on our embedded system.\n",
    "The only difference is we will use the included `tf.lite` module instead of the standalone `tflite-runtime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.lite interpreter\n",
    "import tensorflow as tf  # on embedded device use: import tflite_runtime.interpreter as tflite\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from time import process_time\n",
    "\n",
    "# Labels: 0 = Cat, 1 = Dog\n",
    "model_path = \"cat-dog.tflite\"\n",
    "\n",
    "# For running on tflite-runtime replace this with tflite.Interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "# Embedded devices are memory constrained, so this handles that\n",
    "interpreter.allocate_tensors()\n",
    "# Details about model inputs and outputs\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "input_shape = input_details[0][\"shape\"]\n",
    "\n",
    "# Where test images should be uploaded to\n",
    "dir = \"img/\"\n",
    "# Recursively iterate over all images in directory\n",
    "for root, dirs, files in os.walk(dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".jpeg\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            # Load the image using PIL\n",
    "            image = Image.open(file_path)\n",
    "            # Resize the image to match what the model was trained on\n",
    "            resized_image = image.resize((input_shape[1], input_shape[2]))\n",
    "            input_data = np.array(resized_image, dtype=np.float32)\n",
    "            input_data = np.expand_dims(input_data, axis=0)  # Create a batch of size 1\n",
    "\n",
    "            # Conduct inference\n",
    "            start_time = process_time()\n",
    "            interpreter.set_tensor(input_details[0][\"index\"], input_data)\n",
    "            interpreter.invoke()\n",
    "            output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "            # Pull out the raw value from the np array\n",
    "            prediction = np.squeeze(output_data)\n",
    "            elapsed_time = process_time() - start_time\n",
    "\n",
    "            # Computing exponents for sigmoid function is expensive, so use a simple heuristic instead.\n",
    "            # If  you need an \"unknown\" option or confidence threshold, use something like this.\n",
    "            # label = 0 if prediction < -3 else (1 if prediction > 3 else -1)\n",
    "            label = 0 if prediction < 0 else 1\n",
    "\n",
    "            print(\"Img:\", file)\n",
    "            print(\"Inference time\", elapsed_time)\n",
    "            print(\"Raw prediction:\", result)\n",
    "            print(\"Inferred label:\", sig_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step: Raspberry Pi\n",
    "\n",
    "Now that we know our TF Lite model works, let's put it on an embedded system!\n",
    "\n",
    "Make sure you downloaded your `.tflite` file!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Lite ðŸ¥§\n",
    "\n",
    "Running TensorFlow Lite on a Raspberry Pi\n",
    "\n",
    "## Pre-reading\n",
    "\n",
    "- [The Picamera2 Library](https://datasheets.raspberrypi.com/camera/picamera2-manual.pdf) Chapter 1, 2.1, 2.3.\n",
    "- Skim the titles of [picamer2/examples](https://github.com/raspberrypi/picamera2/tree/main/examples). *(Wait, is that a tensorflow directory??)*\n",
    "\n",
    "> As of mid-September 2022, Picamera2 is pre-installed in all Raspberry Pi OS images.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Practice good software design\n",
    "- Think about and build an input pipeline\n",
    "- Take pics with a pi camera and conduct inference on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get started\n",
    "\n",
    "Remember to upload your `.tflite` model from yesterday.\n",
    "\n",
    "### The plan\n",
    "\n",
    "**Before** you start into the code, draw out what you need to accomplish.\n",
    "\n",
    "### The janky starter code\n",
    "\n",
    "Is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "import numpy as np\n",
    "from picamera2 import Picamera2, Preview\n",
    "from time import sleep\n",
    "\n",
    "# How many pixe\n",
    "capture_shape = (1280, 720)\n",
    "\n",
    "\n",
    "def tflite_infer(interpreter, input_details, input_data):\n",
    "    # Reserve a spot for the result\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], input_data)\n",
    "    # Conduct inference\n",
    "    interpreter.invoke()\n",
    "    # Save results of inference\n",
    "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    # Trim off extra dimensions from result\n",
    "    return np.squeeze(output_data)\n",
    "\n",
    "\n",
    "# Create the tflite Interpreter\n",
    "model_path = \"cat-dog.tflite\"\n",
    "interpreter = tflite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Initialize and start the camera\n",
    "picam2 = Picamera2()\n",
    "camera_config = picam2.create_still_configuration(\n",
    "    main={\"size\": (1920, 1080)}, lores={\"size\": (640, 480)}, display=\"lores\"\n",
    ")\n",
    "picam2.configure(camera_config)\n",
    "# Pop up a preview window\n",
    "picam2.start_preview(Preview.QTGL)\n",
    "\n",
    "# Turn on the camera\n",
    "picam2.start()\n",
    "\n",
    "# Pause for preview\n",
    "sleep(2)\n",
    "\n",
    "# Take a picture\n",
    "np_pic = picam2.capture_array()\n",
    "print(\"np size\", np_pic.shape)\n",
    "# Stop the camera\n",
    "picam2.stop()\n",
    "\n",
    "# Resize picture to be dimensions the TF model expects\n",
    "resized_pic = np.resize(np_pic, input_details[0][\"shape\"])\n",
    "resized_pic = resized_pic.astype(np.float32, copy=False)\n",
    "\n",
    "# Conduct inference\n",
    "infer_result = tflite_infer(interpreter, input_details, resized_pic)\n",
    "\n",
    "print(\"Inference result:\", infer_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
